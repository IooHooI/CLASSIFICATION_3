{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.code.utils import save_obj\n",
    "from source.code.utils import load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 30000)\n",
    "pd.set_option('display.max_columns', 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/dataset/original/{}.csv'\n",
    "processed_data_path = '../data/dataset/processed/{}.csv'\n",
    "profiling_path = '../data/dataset/processed/data_profiling/{}.html'\n",
    "meta_path = '../data/dataset/processed/meta-info/{}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PATTERN = 'n_missing <= 0 & type == \\'{}\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['application_train', 'application_test', 'bureau', 'bureau_balance', 'credit_card_balance', 'installments_payments', 'POS_CASH_balance', 'previous_application', 'sample_submission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n, test_n, bureau_n, bureau_balance_n, credit_card_balance_n, installments_payments_n, POS_CASH_balance_n, previous_application_n, sample_submission_n = 0, 1, 2, 3, 4, 5, 6, 7, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we just load all data into memory, then profile each dataset,\n",
    "\n",
    "then try to filter features that are most interesting for us at the moment\n",
    "\n",
    "(continuous, categorical, binary features without na, features with low na percentage etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict(zip(dataset_names, list(map(lambda name: pd.read_csv(filepath_or_buffer=data_path.format(name)), tqdm(dataset_names)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_description = pd.read_csv(filepath_or_buffer='../data/dataset/original/HomeCredit_columns_description.csv', encoding='ISO-8859-1', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here at this picture the general data structure is reflected.\n",
    "\n",
    "Lots of connections and, as a consequence, lots of hypothetial issues with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of data scheme](https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **application_{train|test}.csv**\n",
    "\n",
    "This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n",
    "Static data for all applications. One row represents one loan in our data sample.\n",
    "\n",
    "- **bureau.csv**\n",
    "\n",
    "All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample).\n",
    "For every loan in our sample, there are as many rows as number of credits the client had in Credit Bureau before the application date.\n",
    "\n",
    "- **bureau_balance.csv**\n",
    "\n",
    "Monthly balances of previous credits in Credit Bureau.\n",
    "This table has one row for each month of history of every previous credit reported to Credit Bureau – i.e the table has (#loans in sample * # of relative previous credits * # of months where we have some history observable for the previous credits) rows.\n",
    "\n",
    "- **POS_CASH_balance.csv**\n",
    "\n",
    "Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n",
    "This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credits * # of months in which we have some history observable for the previous credits) rows.\n",
    "\n",
    "- **credit_card_balance.csv**\n",
    "\n",
    "Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n",
    "This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credit cards * # of months where we have some history observable for the previous credit card) rows.\n",
    "\n",
    "- **previous_application.csv**\n",
    "\n",
    "All previous applications for Home Credit loans of clients who have loans in our sample.\n",
    "There is one row for each previous application related to loans in our data sample.\n",
    "\n",
    "- **installments_payments.csv**\n",
    "\n",
    "Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n",
    "There is a) one row for every payment that was made plus b) one row each for missed payment.\n",
    "One row is equivalent to one payment of one installment OR one installment corresponding to one payment of one previous Home Credit credit related to loans in our sample.\n",
    "\n",
    "- **HomeCredit_columns_description.csv**\n",
    "\n",
    "This file contains descriptions for the columns in the various data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]].head().T # application_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[test_n]].head().T # application_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[bureau_n]].head().T # bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[bureau_balance_n]].head().T # bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[credit_card_balance_n]].head().T # credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[installments_payments_n]].head().T # installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[POS_CASH_balance_n]].head().T # POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[previous_application_n]].head().T # previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[sample_submission_n]].head().T # sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]].info(verbose=10, null_counts=True) # application_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[test_n]].info(verbose=10, null_counts=True) # application_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[bureau_n]].info(verbose=10, null_counts=True) # bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[bureau_balance_n]].info(verbose=10, null_counts=True) # bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[credit_card_balance_n]].info(verbose=10, null_counts=True) # credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[installments_payments_n]].info(verbose=10, null_counts=True) # installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[POS_CASH_balance_n]].info(verbose=10, null_counts=True) # POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dict[dataset_names[previous_application_n]].info(verbose=10, null_counts=True) # previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[sample_submission_n]].info(verbose=10, null_counts=True) # sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace 'Y' and 'N' with 1 and 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of NaNs, lots of features and besides that there are several features that supposed to be binary (and have 0 and 1 values) but they have 'Y' and 'N' values instead.\n",
    "\n",
    "It's better to transforme it into 0 and 1 because some algorithms can work incorrectly with non numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]] = data_dict[dataset_names[train_n]].replace({'Y': 1, 'N': 0})\n",
    "data_dict[dataset_names[test_n]] = data_dict[dataset_names[test_n]].replace({'Y': 1, 'N': 0})\n",
    "data_dict[dataset_names[bureau_n]] = data_dict[dataset_names[bureau_n]].replace({'Y': 1, 'N': 0})\n",
    "data_dict[dataset_names[bureau_balance_n]] = data_dict[dataset_names[bureau_balance_n]].replace({'Y': 1, 'N': 0})\n",
    "data_dict[dataset_names[credit_card_balance_n]] = data_dict[dataset_names[credit_card_balance_n]].replace({'Y': 1, 'N': 0})\n",
    "data_dict[dataset_names[POS_CASH_balance_n]] = data_dict[dataset_names[POS_CASH_balance_n]].replace({'Y': 1, 'N': 0})\n",
    "data_dict[dataset_names[previous_application_n]] = data_dict[dataset_names[previous_application_n]].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually this reports are being displayed in notebooks but since train and test have so many variables\n",
    "\n",
    "it is more convnient to work with report as a Pandas DataFrame which contains meta-information about dataset columns\n",
    "\n",
    "(number of continuous, categorical, binary columns, number of highly correlated columns etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiles_dict = {k: pandas_profiling.ProfileReport(v) for k, v in tqdm(data_dict.items())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to simplify the process we will firstly take those features that do not contain any NaN values and are not highly correlated with other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features = dict(zip(dataset_names, list(map(lambda name: profiles_dict[name].description_set['variables'].query(QUERY_PATTERN.format('NUM'))['type'].index.values, dataset_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cat_features = dict(zip(dataset_names, list(map(lambda name: profiles_dict[name].description_set['variables'].query(QUERY_PATTERN.format('CAT'))['type'].index.values, dataset_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_bin_features = dict(zip(dataset_names, list(map(lambda name: profiles_dict[name].description_set['variables'].query(QUERY_PATTERN.format('BOOL'))['type'].index.values, dataset_names))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique values counts of categorical features in train & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was seen from the previous cells there are a lot of caterical features in train/test parts.\n",
    "\n",
    "Apparently we will have to binarize them.\n",
    "\n",
    "But it is unclear whether all categories for particular feature exist both in train & test.\n",
    "\n",
    "If no then it can cause problem because the number of binarized features would be different in train & tets in this case,\n",
    "\n",
    "so we have to check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[train_n]].description_set['variables'][profiles_dict[dataset_names[train_n]].description_set['variables'].index.isin(datasets_cat_features[dataset_names[train_n]])]['distinct_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[test_n]].description_set['variables'][profiles_dict[dataset_names[test_n]].description_set['variables'].index.isin(datasets_cat_features[dataset_names[test_n]])]['distinct_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see CODE_GENDER, NAME_FAMILY_STATUS and NAME_INCOME_TYPE have different number of distinct values.\n",
    "\n",
    "We save intersections distinct values sets for these features to be sure that after binarization train & test will have equal number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by the way CODE_GENDER and NAME_CONTRACT_TYPE apparently should by binary variable but it has 3 distinct values in train part.\n",
    "\n",
    "Let's look at those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]]['CODE_GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[test_n]]['CODE_GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]]['NAME_CONTRACT_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[test_n]]['NAME_CONTRACT_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 4 objects for 'XNA' value?\n",
    "\n",
    "No, this is not worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]] = data_dict[dataset_names[train_n]][data_dict[dataset_names[train_n]].CODE_GENDER.isin(['M', 'F'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]]['CODE_GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]] = data_dict[dataset_names[train_n]].replace({'F': 1, 'M': 0})\n",
    "data_dict[dataset_names[test_n]] = data_dict[dataset_names[test_n]].replace({'F': 1, 'M': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[dataset_names[train_n]] = data_dict[dataset_names[train_n]].replace({'Cash loans': 1, 'Revolving loans': 0})\n",
    "data_dict[dataset_names[test_n]] = data_dict[dataset_names[test_n]].replace({'Cash loans': 1, 'Revolving loans': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we can re-profile train & test part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict[dataset_names[train_n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[train_n]] = pandas_profiling.ProfileReport(data_dict[dataset_names[train_n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[test_n]] = pandas_profiling.ProfileReport(data_dict[dataset_names[test_n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features = dict(zip(dataset_names, list(map(lambda name: profiles_dict[name].description_set['variables'].query(QUERY_PATTERN.format('NUM'))['type'].index.values, dataset_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cat_features = dict(zip(dataset_names, list(map(lambda name: profiles_dict[name].description_set['variables'].query(QUERY_PATTERN.format('CAT'))['type'].index.values, dataset_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_bin_features = dict(zip(dataset_names, list(map(lambda name: profiles_dict[name].description_set['variables'].query(QUERY_PATTERN.format('BOOL'))['type'].index.values, dataset_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_bin_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features[dataset_names[train_n]] = datasets_num_features[dataset_names[train_n]][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features[dataset_names[train_n]] = np.append(datasets_num_features[dataset_names[train_n]], 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(datasets_num_features, meta_path.format('datasets_num_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(datasets_cat_features, meta_path.format('datasets_cat_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(datasets_bin_features, meta_path.format('datasets_bin_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commom_categories = {}\n",
    "for feature in tqdm(datasets_cat_features[dataset_names[train_n]]):\n",
    "    commom_categories[feature] = list(set(data_dict[dataset_names[train_n]][feature].unique()) & set(data_dict[dataset_names[train_n]][feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(commom_categories, meta_path.format('commom_categories'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store all these reports in case.\n",
    "\n",
    "Also it would be reasonable to store all meta-information to be able not to recalculate it each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store visual (html) reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_bin_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(lambda name: profiles_dict[name].to_file(outputfile=profiling_path.format(name)), tqdm(dataset_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store reports with feature meta-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(lambda name: save_obj(profiles_dict[name].description_set['variables'], meta_path.format(name)), tqdm(dataset_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just take a look at keys of profiling report dictionary for train (yes, dictionaries, dictionaries and, once again, dictionaries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[train_n]].description_set.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=profiles_dict[dataset_names[train_n]].description_set['variables'].columns.values, columns=['PROFILING_VARIABLES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the report contains a value with the 'variables' key.\n",
    "\n",
    "The value is a Pandas DataFrame which contains informations about each column of the dataset.\n",
    "\n",
    "Each column is described with features displayed above.\n",
    "\n",
    "Let's take a closer look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[train_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[train_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[train_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[train_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have probably guessed that the whole count of columns is the sum of count of columns with 'CORR' type and count of columns with some number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[test_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[test_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[test_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[test_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(profiles_dict[dataset_names[train_n]].description_set['variables'].index) - set(profiles_dict[dataset_names[test_n]].description_set['variables'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this time the whole count of columns is 1 columns less because test dataset does not contain TARGET column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUREAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[bureau_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[bureau_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[bureau_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[bureau_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUREAU BALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[bureau_balance_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[bureau_balance_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[bureau_balance_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[bureau_balance_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT CARD BALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[credit_card_balance_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[credit_card_balance_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[credit_card_balance_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[credit_card_balance_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALLMENTS PAYMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[installments_payments_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[installments_payments_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[installments_payments_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[installments_payments_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS CASH BALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[POS_CASH_balance_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[POS_CASH_balance_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[POS_CASH_balance_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[POS_CASH_balance_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREVIOUS APPLICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[previous_application_n]].description_set['variables']['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[previous_application_n]].description_set['variables']['n_missing'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiles_dict[dataset_names[previous_application_n]].description_set['variables']['p_missing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(profiles_dict[dataset_names[previous_application_n]].description_set['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we can say that every dataset has some problems with data quality.\n",
    "\n",
    "It is possble to highlight two major issues at the moment:\n",
    "- NAs;\n",
    "- high corelation.\n",
    "\n",
    "Perhaps (even very likely) there are other issues but that is not clear so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And finally (but not at all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save datasets without NaNs to make data a bit more compact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features_list = datasets_num_features[name].tolist() + datasets_cat_features[name].tolist() + datasets_bin_features[name].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(lambda name: data_dict[name][final_features_list].to_csv(processed_data_path.format(name), index=False), tqdm(dataset_names)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
