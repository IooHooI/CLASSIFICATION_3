{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.code.utils import load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.code.utils import generate_pipeline\n",
    "from source.code.utils import generate_cat_feature_counts\n",
    "from source.code.utils import generate_features_names\n",
    "from source.code.ItemSelector import ItemSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 30000)\n",
    "pd.set_option('display.max_columns', 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/dataset/processed/{}.csv'\n",
    "transformed_data_path = '../data/dataset/transformed/{}.csv'\n",
    "meta_path = '../data/dataset/processed/meta-info/{}.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we just load all data into memory, then profile each dataset,\n",
    "\n",
    "then try to filter features that are most interesting for us at the moment\n",
    "\n",
    "(continuous, categorical, binary features without na, features with low na percentage etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['application_train', 'application_test', 'bureau', 'bureau_balance', 'credit_card_balance', 'installments_payments', 'POS_CASH_balance', 'previous_application', 'sample_submission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict(zip(dataset_names, list(map(lambda name: pd.read_csv(filepath_or_buffer=data_path.format(name)), tqdm(dataset_names)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_num_features = load_obj(meta_path.format('datasets_num_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cat_features = load_obj(meta_path.format('datasets_cat_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_bin_features = load_obj(meta_path.format('datasets_bin_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_features_list = list(map(lambda name: generate_features_names(\n",
    "    datasets_bin_features[name].tolist(),\n",
    "    generate_cat_feature_counts(data_dict[name], datasets_cat_features[name].tolist()),\n",
    "    datasets_num_features[name].tolist()\n",
    "), tqdm(dataset_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list(\n",
    "    map(\n",
    "        lambda name: Pipeline([\n",
    "            ('union', FeatureUnion(\n",
    "                [('bin', Pipeline([('choose', ItemSelector(datasets_bin_features[name].tolist()))]))] +\\\n",
    "                list(map(generate_pipeline, datasets_cat_features[name].tolist())) +\\\n",
    "                [('num', Pipeline([('choose', ItemSelector(datasets_num_features[name].tolist()))]))]\n",
    "            ))]),\n",
    "        tqdm(dataset_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_tr = list(map(lambda name_number: pd.DataFrame(pipelines[name_number].fit_transform(data_dict[dataset_names[name_number]]), columns=extended_features_list[name_number]), tqdm(range(len(dataset_names)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_dict = dict(zip(dataset_names, datasets_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(lambda name: tr_data_dict[name].to_csv(transformed_data_path.format(name), index=False), tqdm(dataset_names)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
